{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6df7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Model, Input\n",
    "from sequence_generator import SequenceGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, MaxPooling2D,\n",
    "                                     GlobalAveragePooling2D, Dense, Dropout, TimeDistributed, LSTM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path= \"...dataset_SPT_lstm/metadata_SPT_images_sequences.csv\"\n",
    "root_path = \"...dataset_SPT_lstm/images_SPT_sequences/\"\n",
    "\n",
    "class_names = ['EXPLOSION', 'NO_EXPLOSION', 'NO_SIGNAL', 'SPATTERING']\n",
    "\n",
    "batch_size = 32\n",
    "seq_length = 100\n",
    "img_size = (128,128)\n",
    "classes = len(class_names)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_dataset = pd.read_csv(csv_path)\n",
    "train_split = 0.7\n",
    "df_train = df_full_dataset.sample(frac=train_split,\n",
    "                                  random_state=42)\n",
    "\n",
    "df_val = df_full_dataset.drop(df_train.index)\n",
    "\n",
    "train_generator = SequenceGenerator(df_train, \n",
    "                                    root_path,\n",
    "                                    seq_length=seq_length,\n",
    "                                    img_size=img_size,\n",
    "                                    classes=classes,\n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True)\n",
    "\n",
    "validation_generator = SequenceGenerator(df_val,\n",
    "                                         root_path,\n",
    "                                         seq_length=seq_length,\n",
    "                                         img_size=img_size,\n",
    "                                         classes=classes,\n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y = next(iter(train_generator)) \n",
    "\n",
    "seq_idx = 0        \n",
    "start_frame = 45     \n",
    "num_frames = 11  \n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(num_frames):\n",
    "    plt.subplot(1, num_frames, i + 1)\n",
    "    frame_idx = start_frame + i\n",
    "    plt.imshow(x[seq_idx, frame_idx][..., ::-1], interpolation='none')\n",
    "    clase_idx = np.argmax(y[seq_idx, frame_idx])\n",
    "    plt.title(\"Frame:\" +str(frame_idx)+\"\\n\"+str(class_names[clase_idx]), fontsize=9)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build the cnn model \n",
    "\n",
    "def cnn_stromboli_model(input_shape_2d=(128,128,3)):\n",
    "    inputs = Input(shape=input_shape_2d)\n",
    "\n",
    "    conv1 = Conv2D(4, (4,4), strides=(2,2), padding='same', activation='relu')(inputs)\n",
    "    batch1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(batch1)\n",
    "\n",
    "    conv2 = Conv2D(4, (3,3), strides=(2,2), padding='same', activation='relu')(pool1)\n",
    "    batch2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(batch2)\n",
    "\n",
    "    conv3 = Conv2D(8, (3,3), strides=(2,2), padding='same', activation='relu')(pool2)\n",
    "    batch3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(batch3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3,3), strides=(2,2), padding='same', activation='relu')(pool3)\n",
    "    batch4 = BatchNormalization()(conv4)\n",
    "    pool4 = GlobalAveragePooling2D()(batch4)\n",
    "     \n",
    "\n",
    "\n",
    "    flatten1 = Dense(512, activation='relu')(pool4)\n",
    "    drop1 = Dropout(0.5)(flatten1)\n",
    "\n",
    "    model = Model(inputs, drop1, name=\"CNN_model\")\n",
    "    return model\n",
    "\n",
    "## Build the td_cnn_lstm model \n",
    "\n",
    "def cnn_lstm_stromboli_model(input_shape, classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    cnn_base_model = cnn_stromboli_model(input_shape_2d=(input_shape[1], input_shape[2], input_shape[3]))\n",
    "    cnn_base_model.trainable = True\n",
    "\n",
    "    tdcnn_features = TimeDistributed(cnn_base_model)(input_tensor)\n",
    "\n",
    "    lstm_1 = LSTM(units=256, return_sequences=True, dropout=0.5)(tdcnn_features)\n",
    "    lstm_2 = LSTM(units=128, return_sequences=True, dropout=0.5)(lstm_1)\n",
    "    \n",
    "    classify = TimeDistributed(Dense(classes, activation='softmax'))(lstm_2)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=classify)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (seq_length, *img_size, 3)\n",
    "model = cnn_lstm_stromboli_model(input_shape, classes)\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiler\n",
    "\n",
    "checkpoint= tf.keras.callbacks.ModelCheckpoint('... path_to_SAve_model .keras', \n",
    "                                              save_best_only=True, \n",
    "                                              monitor='val_loss')\n",
    "\n",
    "stop= tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                       patience=5)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1692cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[checkpoint, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots trends metrics\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(221)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Loss function TD-CNN-LSTM')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss function', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Accuracy TD-CNN-LSTM')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.zeros((classes, classes), dtype=np.int64)\n",
    "\n",
    "#with tf.device(\"/CPU:0\"): \n",
    "for i in range(len(validation_generator)):\n",
    "    Xb, yb = validation_generator[i]\n",
    "    pb = model.predict(Xb, batch_size=1, verbose=0)\n",
    "\n",
    "    yt = np.argmax(yb, axis=-1).ravel()\n",
    "    yp = np.argmax(pb, axis=-1).ravel()\n",
    "\n",
    "    cm += confusion_matrix(yt, yp, labels=range(classes))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Confusion Matrix (Frame)\")\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(class_names)), class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "thr = cm.max() / 2 if cm.max() else 0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, f\"{int(cm[i, j])}\", ha=\"center\", va=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thr else \"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
