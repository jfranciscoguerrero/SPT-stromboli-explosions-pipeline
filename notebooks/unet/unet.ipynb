{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n",
    "\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2 as cv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import paths\n",
    "path_train_img ='/.../training/images/images/'\n",
    "path_train_mask='/.../training/mask/mask/'\n",
    "\n",
    "path_val_img ='/.../validation/images/images/'\n",
    "path_val_mask = '/.../validation/mask/mask/'\n",
    "\n",
    "##test Images\n",
    "image_train = cv.imread(path_train_img +\"1.png\")\n",
    "mask_train = cv.imread(path_train_mask +\"1.png\")\n",
    "\n",
    "img_color= np.array(image_train)\n",
    "mask=np.array(mask_train)\n",
    "mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "len_training= len(os.listdir(path_train_img))\n",
    "print(\"len_train\",len_training)\n",
    "len_validation= len(os.listdir(path_val_img))\n",
    "print(\"len val\",len_validation)\n",
    "print(\"shape color img\",img_color.shape)\n",
    "print (\"shape mask:\",mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27793b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221)\n",
    "plt.title(\"cropped Imgage by RetinaNet Network\")\n",
    "plt.imshow(img_color)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Ground thrut mask\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##segmentation_preprocessing\n",
    "from segmentation import SegmentationGenerator\n",
    "\n",
    "num_classes=5\n",
    "batch_size=8\n",
    "size= 512\n",
    "print(size)\n",
    "\n",
    "step_per_epoch_ = len_training//batch_size\n",
    "step_validation= len_validation//batch_size\n",
    "\n",
    "print(step_validation)\n",
    "\n",
    "train_generator= SegmentationGenerator(path_train_img,\n",
    "                                      path_train_mask,\n",
    "                                      num_classes=num_classes,\n",
    "                                      rescale=1./255,\n",
    "                                      target_size=(size,size),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True)\n",
    "\n",
    "val_generator= SegmentationGenerator(path_val_img,\n",
    "                                     path_val_mask,\n",
    "                                     num_classes=num_classes,\n",
    "                                     rescale=1./255,\n",
    "                                     target_size=(size,size),\n",
    "                                     batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c12412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_lava_flow_unet(pretrained_weights=None, input_size=(size,size,3)):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(16,3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(16,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(32,3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(32,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(64,3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(64,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(128,3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(128,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256,3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(256,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2,2))(conv5)\n",
    "    \n",
    "    conv6 = Conv2D(512,3, activation='relu', padding='same', kernel_initializer='he_normal')(pool5)\n",
    "    conv6 = Conv2D(512,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    drop6 = Dropout(0.5)(conv6)\n",
    "    \n",
    "    '''DECODER'''\n",
    "    \n",
    "    up7= Conv2DTranspose(256,3, strides=(2, 2), padding='same')(drop6)\n",
    "    merge7= concatenate([conv5,up7])\n",
    "    conv7= Conv2D(256,3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7= Conv2D(256,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8= Conv2DTranspose(128,3,  strides=(2, 2),padding='same',)(conv7)\n",
    "    merge8= concatenate([conv4,up8],axis=3)\n",
    "    conv8= Conv2D(128,3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8= Conv2D(128,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    \n",
    "    up9= Conv2DTranspose(64,3,  strides=(2, 2), padding='same', )(conv8)\n",
    "    merge9= concatenate([conv3,up9],axis=3)\n",
    "    conv9= Conv2D(64,3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9= Conv2D(64,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    up10= Conv2DTranspose(32,3,  strides=(2, 2), padding='same')(conv9)\n",
    "    merge10= concatenate([conv2,up10],axis=3)\n",
    "    conv10= Conv2D(32,3, activation='relu', padding='same', kernel_initializer='he_normal')(merge10)\n",
    "    conv10= Conv2D(32,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\n",
    "    \n",
    "    up11= Conv2DTranspose(16,3,  strides=(2, 2), padding='same')(conv10)\n",
    "    merge11= concatenate([conv1,up11],axis=3)\n",
    "    conv11= Conv2D(16,3, activation='relu', padding='same', kernel_initializer='he_normal')(merge11)\n",
    "    conv11= Conv2D(16,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "    conv11= Conv2D(16,3, activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "    \n",
    "    classify= Conv2D(5,1, activation='softmax')(conv11)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[classify])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03728d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stromboli_unet = mapping_lava_flow_unet()\n",
    "stromboli_unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop= tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                       patience=10)\n",
    "\n",
    "stromboli_unet.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy',iou_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = stromboli_unet.fit(train_generator,\n",
    "                                validation_data=val_generator,\n",
    "                                steps_per_epoch=step_per_epoch_,\n",
    "                                validation_steps=step_validation,\n",
    "                                callbacks=[stop],\n",
    "                                epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss function')\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Loss function U-Net model Stromboli')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Accuracy U-Net model Stromboli')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "#stromboli_unet.save('D:/unet_traided_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#stromboli_unet= load_model('D:/unet_traided_model.h5',custom_objects= {'iou_score': iou_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a53667",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, val_iou= stromboli_unet.evaluate(val_generator,\n",
    "                                                 steps=int(len(val_generator)/4))\n",
    "print('extactidu es:', format(100*val_acc,'.2f'),'%')\n",
    "print('IOU es', format(100*val_iou,'.2f'),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU for each image\n",
    "def calculate_iou_per_image(y_true, y_pred, num_classes=5):\n",
    "    y_true = np.argmax(y_true, axis=-1).flatten()\n",
    "    y_pred = np.argmax(y_pred, axis=-1).flatten()\n",
    "\n",
    "    iou_metric = MeanIoU(num_classes=num_classes)\n",
    "    iou_metric.update_state(y_true, y_pred)\n",
    "    return iou_metric.result().numpy()\n",
    "\n",
    "iou_scores = []\n",
    "\n",
    "\n",
    "for i, (x_val, y_true) in enumerate(val_generator):\n",
    "    y_pred = stromboli_unet.predict(x_val)\n",
    "    iou_score = calculate_iou_per_image(y_true, y_pred)\n",
    "    iou_scores.append(iou_score)\n",
    "    print(f\"Image {i+1} - IoU: {iou_score:.4f}\")\n",
    "\n",
    "    if i >= len(val_generator) - 1:\n",
    "        break\n",
    "\n",
    "# Calculate the mean IoU score\n",
    "mean_iou = np.mean(iou_scores)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iou_scores, marker='o', linestyle='-', color='b', label='IoU per Image')\n",
    "plt.axhline(y=mean_iou, color='r', linestyle='--', label=f'Mean IoU: {mean_iou:.4f}')\n",
    "plt.title('Mean IoU Score for 250 Batches')\n",
    "plt.xlabel('Image Index')\n",
    "plt.ylabel('IoU Score')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
